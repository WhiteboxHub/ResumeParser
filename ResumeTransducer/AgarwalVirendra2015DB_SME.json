{"skills":[{"Languages":": English, German, Slovak, and Hindi\n\n"},{"Technologies":" used: Unix\/Ksh\/Perl\/SQL\/Java\/AJAX\/AFS, Autosys, Perforce, RCS Source Control\n\n"},{"Expertise":" in iso_1 to utf8 data migration in Sybase Servers.\n\nDeveloped migration scripts, and Autosys jobs under Unix, Ksh\/Perl \/jil \/JDBC.\n\nData mining of client\/employee interactions via EMAIL\/Phone data and providing Text Search capability using Sybase\/Verity.\n\nFamiliar with ASE 15.x features.\n\nDatabase Administration involving Replication under Unix\/Sybase\/Perforce. Supported several Production ASE 12.5.x UTF8\/ISO_1 Servers along with some DEV\/QA servers which included building\/installing new Servers, Configuring system parameters, adding\/initializing databases, creating\/dumping (backup)\/loading databases.\n\nSet up replication definitions\/subscriptions, re-synching Primary and Replicate databases. Setting\/Rebasing Warm Standbys, Setting up bidirectional replication.\n\nPerformance tuning\/Monitoring of ASE's and Replication Servers and handling day to day user SQL Replication\/performance issues.\n\nDeployment of DB schema, Stored Procedures, Triggers in ASEs.\n\nPerforming logical backup using bcp needed for data migration between ISO_1 and UTF8 Servers. Familiar with ASE 15.x features.\n\n"}],"work":[{"summary":"\n\nArchitected\/Modeled(logical\/physical) Trade and Fixed Income Investment Securities using Erwin r9.5\/MS and implemented on MS SQL Server 2012 using SSMS, Batch\/Powershell scripts, Stored Procedures\/DDLs.\n\nBuilt SSIS package on MS SQL Management studio for deployment. Database Logical\/physical design, creation of Tables\/Views\/Stored Procedures.\n\nLed the Chef installation of SqlServer and following HedgeServ customizations for repeatable automated setup, targeting many hundreds of Dev, QA, UAT and Prod cloud VMs.\n\nEnforced Reusability, refactoring for clean and simple code, Agile Methodology, Source Code control using CVCS(SVN) and DVCS (GITHUB)\n\nDeveloped a stored procedure to generate generic Select\/Insert\/Update\/Delete stored procedure for a table under Windows MS SQL 2012 environment. Developed Backup\/Recovery procedures using Back\/Restore utilities to implement Simple\/Full\/AlwaysOn scenerios as per business requirements. Scheduled Backup tasks using SSMS tasks menu.\n\nSource code control using MS Team Foundation Server.\n\nWorked with R programming, a Statistical analysis tool, GitHub SCCS using command line git bash for windows\/ git f or Unix.\n\nPig Latin relational algebra data flow language suitable for ETL ( Load\/dump\/group\/Filter\/cogroup\/join\/foreach\/distinct\/union\/store etc.) over Map\/Reduce with Schema on \u2018read\u2019 (as opposed to RDBMS which schema on write) simplifying Map\/Reduce low level Java programming without losing performance, processing \u2018in-situ\u2019 data.\n\nWorked with Pig Latin, HiveQL, R, and Cloudera Sqoop over core Hadoop HDFS\/Map\/Reduce clusters for distributed processing\/analysis with single NameNode controlling multiple DataNodes using JobTracker\/TaskTracker daemons configured with Zookeeper\/Ambari XML core\/hdfs\/mapred-site config files.\n\nHadoop with Query (HAWQ\/psql) native to HDFS like MPP DB Greenplum Postgres Style SQL without MapReduce unlike Hadoop\/Hive for faster queries. Unlike Greenplum HAWQ supports external tables but no UPDATE\/DELETE. Aided by Apache SPARK in-memory processing with HDFS for faster processing than HQL. Familiar with gpfdist (insert from external table into Greenplum table)\/gpload (YAML format \u2013 requires pygresql\/pyyaml, invokes gpfdist and creates external table as per source and loads in target) utilities to load data in Greenplum DB.\n\nFamiliar with use of SQL OVER (PARTITION BY .. ORDER BY ..) clause in conjunction with various Analytical\/Ranking\/Aggregate functions which include RANK(), DENSE_RANK(),PERCENT_RANK(),NTILE(n),ROW_NUMBER(), AVG, SUM() etc. which generate output without need of self-join.\n\nFamiliar with DB2 Q- Replication using Q-Capture\/SrcQMgr \/Tgt QMr\/Q-Apply using Websphere MQ Channels, Creating 4 queues at each source\/Target Q- managers, defining sender\/receiver channels at both Q-mgrs, Start Webshpere MQ channels\/listners,setting up control tables for Q-Capture\/Apply programs, enable source DB replication, creating replication Q-Map, Q-Subscription, starting replication between source and target.\n\n","position":"Developer","startDate":"3\/2014","endDate":"11\/2015"},{"summary":" event and time based job scheduling using Autosys\/JIL and Unix Cron tool.\n\nData Modeling\/Design, Development of DDL, Data Extraction SQL code for TERADATA 13.x, UDB DB2, and Hadoop\/Hive (Big Data), systems under AIX\/Linux using Ksh, Perl, Teradata utilities BTEQ, FEXP, TPT (tbuild), FastLoad,MultiLoad,TPUMP, HiveQL, Sqoop, Hadoop dfs for CREDIT CARD SERVICES.\n\nWorked with Pig Latin, HiveQL, R, and Cloudera Sqoop over core Hadoop HDFS\/Map\/Reduce clusters for distributed processing\/analysis with NameNode\/DataNode\/JobTracker\/TaskTracker daemons configured using Zookeeper XML core\/hdfs\/mapred-site config files.\n\nData modeling using Sybase Power Designer 15.x, TOAD 4.7.x, and ERWIN r8 to reverse engineer DB2 and Teradata Database objects. Worked with Teradata SQL Assistant, BTEQWin windows applications.\n\nDeveloped Perl OO modules for DDL and Data Extraction\/Load for Teradata using Teradata catalog tables and BTEQ\/FEXP\/TPT\/FastLoad(1 table) \/MLOAD(5 tables)\/TPUMP methods and loading into Hive\/Hadoop. Familiar with Primary, 32 Secondary, join, AJI indexes. Familiar with Teradata Unity\/NPAM Data Mover utility to move\/copy objects. Familiar with Collect\/Drop Stats, EXPLAIN for query plan, HELP for any help on data objects and SQL commands. Familiar with Temporal data type Period DATE\/Timestamp which include Closed\/Open range helping in dimensional modeling with slowly changing dimensions.\n\nDynamically generated the SQL from Teradata Catalog tables\/Views DBC.< tables|columns|indices > for data extraction as concatenated string of all columns. Teradata Database Query Log (DBQL) saves performance data in DBQLogtbl\/SessionTbl.\n\nTeradata Administration using WinDDI (Windows Data Dictionary Interface) similar to DBArtisan XE4.\n\nEvent based Job scheduling via Autosys 4.5 using JIL, autorep, sendevent etc. on AIX\/Linux and time based scheduling using Unix cron. Built many Unix Ksh utilities for operations\/administration etc.\n\nUsed log4J Perl module for 5 logging levels selectively to screen and files. Used Perl DBD\/DBI for Sybase and sybperl using CTLIB\/DBLIB (connect\/prepare\/execute\/fetch).\n\nFamiliar with (FSLDM 7.0) Financial Services Logical Data Model providing single view semantic layer for Enterprise wide data warehousing solution to retail and commercial banking\/brokerage\/insurance companies providing Basel I\/II\/III regulatory Risk management, Asset\/Liability Management. It can handle Federated Data Marts with multiple fact tables sharing (conformed) same standardized dimensions.\n\nFamiliar with IBM BI App Cognos 8, Cognos 10 (integrated with SPSS for statistical analysis, Lotus for Mobile Apps) which provides Database semantic modeling using Framework Manager, ReportStudio for report generation, (Query\/Analysis)Studio for adhoc queries storing aggregate data in MOLAP for lightweight fast response as opposed to IBM Infosphere\/Datastage which are used for High Volume data. For example: 1 fact table (sales), and 3 dimensions (agents, regions, quarters).\n\nConversion of Relational model (keeps traces of transactions) to Dimensional model (keeps effects of transactions for ETL\/DSS applications). Use of surrogate keys, and temporal data type PERIOD (Date\/Timestamp) for keeping slowly changing dimensions of type 0-6 to maintain history, and consistency in dimensions\/measures\/facts data.\n\nFamiliar with NoSQL non-relational, schema-free, horizontally scalable using document oriented store like MongoDB supports map(extracting data)\/reduce(data aggregation), indexing on any attribute or CouchDB a JSON (JavaScript Object Notation i.e. Attribute=Value) type Document oriented store.\n\nFamiliar with Unified Modeling Language (UML): use case (requirements), state (interactions\/workflow), logical (classes in system), physical component(software)\/deployment(software\/hardware) models.\n\nFamiliar with Data Virtualization methodology for adaptive rapid development like Scrum Agile methodology, IBM Rational Application Development (RAD) etc.\n\nDB Consultant at various Defense contractors (e.g. ","position":"monitor","startDate":"8\/27\/2011","company":"Bank of America","endDate":"3\/31\/2013"},{"summary":"\n\nDeveloped\/Implemented Stored Procedures\/DDLs\/Scripts using Sybase ASE15.5, DB2, and Teradata13.x under Linux, Ksh, Perl5.14, Python3.3.2, Jython2.5.3, Autosys11.x, perforce, JIRA6.0\/Falcon issue tracker, MS Sharepoint2013 for regulatory compliance requirements W, section 223.3(d,u) 23A\/B screening (10%\/20% limit, mark to market, safe\/good quality) for daily trades between Morgan Stanley and affiliates\/subsidiaries conforming to SDLC standards.\n\nData Warehousing using DB2 as target in Type 2 sourcing past trade data in Sybase for generating compliance reports as needed using Erwin and Informatica.\n\nDeveloped Ksh\/Perl\/Python scripts for several tasks related to risk and SEC compliance REG \u201CW\u201D.\n\nSet up and monitor event and time based job scheduling using Autosys\/JIL and Unix Cron tool.\n\nBuilt SOAPtk Perl program to extract trade files from archives on demand.\n\nBuilt Data Warehouse of historical data using facts\/dimension tables on DB2 to recreate compliance reports from the past trade data by migrating data\/schema from Sybase ASE 15.5 to DB2 LUW 9.7 using db2 load\/export utilities under Unix\/ksh, DBArtisan9.1.2, IBM Data Studio 3.1.1, Erwin r7.3, and Sybase Power Designer 16.5.\n\nLed the Chef installation of SqlServer and following HedgeServ customizations for repeatable automated setup, targeting many hundreds of Dev, QA, UAT and Prod cloud VMs.\n\nEnforced Reusability, refactoring for clean and simple code, Agile Methodology, Source Code control using CVCS(SVN) and DVCS (GITHUB)\n\nData modeling and reverse engineer using Erwin\/Subject areas. Enforced naming standards for Logical->physical via Erwin Tools->standards using glossary of words for Prime(entity)\/modifier(attribute qualifier)\/class (attribute).\n\nExtract\/Transform\/Load data from Sybase(Source) to DB2(Target) using Informatica 8.6.1 Power Designer\/Repository Manager\/Workflow Manager\/Monitor for Source to target Mappings\/Maplets\/transformations between Sybase and DB2.\n\n","startDate":"4\/2013","company":"Morgan Stanley","endDate":"12\/2013"},{"summary":", Database Architect\/Designer\/Developer\/Administrator\n\nHands on as well as managed a team of five in Canada\/India, doing Database development\/Administration\/ETL to extract Data from LDAP and transformed\/applied to Contact and reference Data. Supported all Business units including Prime Brokerage and Equities. Familiar with all option derivatives.\n\nArchitected database logical\/physical design, infrastructure tools, and data modeling using ERWIN for core contacts\/relationship data in CRM Applications for CIS (Client Information Systems).\n\nUse of source control perforce for source control, release management, and Falcon for bug tracking.\n\nEvent job scheduling using Autosys and time-based job scheduling using Unix cron .\n\nManaged Development, QA, UAT, Production database environments.\n\nDeveloped\/debugged\/improved Stored Procedures\/Triggers in T-SQL. Source code control used Perforce. Set T-SQL coding standards.\n\nArchitected Migration of Database Servers 12.5.x Infrastructure from ISO8859-1 to UTF8 used by Business Units across the firm in all geographical regions using Linux Machines with failover. ","position":"Vice President","startDate":"8\/2008","company":"MORGAN STANLEY"},{"summary":"\n\nData Analysis, Migration, Integration tools, Data Modeling, Metadata management for various RDBMSs like Teradata, Hadoop\/Hive, DB2, Sybase.MySQL,Oracle, MS SQL.\n\nDesign of Entity diagram, schema design (physical\/logical) using CA Erwin and BMC ER Studio, and converting to database relational tables.\n\nArchitecting database with deploying physical schema and use of ETL tools like Informatica similar to SSIS from Microsoft for MSSQL.\n\nUse of cvs for source control, release management, and bug tracking.\n\nEvent job scheduling using Autosys and time-based job scheduling using Unix cron .\n\nManaged Development, QA, UAT, Production database environments.\n\nDevelopment of Sybase Database Stored Procedures under ASE 12.5.x\/Unix for Contacts Database.\n\nDatabase development, stored procedures, triggers\n\nFamiliar with Database Migration tools like Oracle SQL Developer Migration Workbench, and SwisSQL to migrate Sybase to Oracle databases.\n\nBuilt database tools under Unix using T-SQL\/Ksh\/Perl and database utilities like bcp, ddlgen, defncopy\n\nASE 12.5.x Sybase Database Administration and Replication Server 12.5 Admin. Building new server, upgrading existing ones, applying ebf\u2019s, backup\/recovery procedures.\n\nSybase Database performance and tuning using MDA tables, and monitoring tools\n\nUnix System Performance tuning using commands like ipcs, ipcrm, netstat, nslookup, top, vmstat, iostat etc.\n\nDeveloped Real Time data processing application C\/C++\/TCP socket programming for building server and client. Use of Client socket\/connect\/send\/recv, Server socket\/bind\/listen\/accept\/recv\/send commands. Socket connection made up of 5-tuple (Proto,localaddr,localport, foreignaddr, foreignport).\n\nCore Java programming using object oriented design techniques. Developed Android Application under Windows7\/Eclipse3.7.1\/Java7\/Dalvik and iOS 5.1 Application under Xcode4.3\/MacOS X10.7.3\/Objective-C\n\nCISCO NAT Programming to set up Routers\/Firewalls. ip nat <inside|outside|pool> <source|destination>, show ip nat <statistics|translations>\n\n","startDate":"8\/2011","company":"Northrop"},{"summary":"\n\nArchitecting database logical\/physical design and infrastructure tools.\n\nUse of source control VSS for source control, release management, and Falcon for bug tracking.\n\nEvent job scheduling using Control-M and time-based job scheduling using Unix cron .\n\nSybase DB\/Replication Admin, under Sun\/Solaris 2.8, HP-UX 11.x, Linux .\n\nApache Web Server 2.0.45\/Tomcat, Apache 1.3.27\/Jserv 1.1.2 build\/install on HP\/Solaris.\n\nInstalled Autosys\/Java Interface 4.x\n\nDatabase design using ER Studio\/DBArtisan, Stored Procedures to access\/update\/insert data into tables.\n\nPerl script for extraction of data in XML format for navigational search.\n\nVarious types of feeds processing\/extracting\/manipulating to\/from database for publish\/subscribe.\n\nHeavy Perl\/Ksh\/Stored Procedures utilities for DB Admin\/Applications use.\n\nPerformance Tuning of Stored Procedures SQL queries.\n\nSource code control using CVS.\n\nDeveloped SQL code on Oracle PL\/SQL, SQL*Plus , and MySQL servers.\n\nDB consultant at SUN MICRO SYSTEMS\/Moodys 4\/1998 to 2\/2003\n\nEvent job scheduling using Control-M and time-based job scheduling using Unix cron .\n\nSybase ASE DBA\/Replication DBA under AIX\/SP2 systems supporting various ETL applications.\n\nBuilt Ksh utilities and system stored procedures for DB Admin like addling\/locking\/dropping\/syncing logins, displaying the SQL server info like device info, database info in a suitable format from all development\/Production SQL servers.\n\nInstalled\/configured\/Set up backup\/recovery procedures using SQL backtrack 4.1. Set up procedures for software tools distribution using rdist across SQL Server machines.\n\nSet up procedures for dump\/load\/bcp of databases\/objects from source to target. VSS for source control.\n\nData-warehousing project led to consolidating enterprise wide information, presented via website to its customers. It included extraction of data from various sources, transformation of the information, and loading\/replicating of the information in OLAP environment on a website at Moody\u2019s Investor Service.\n\nConversion from Informix\/Oracle to Sybase.\n\nAutomated adding of raw UNIX devices to the ASE server using shell script identifying raw devices owned by Sybase on the machine that is not already defined in the ASE Server.\n\nMerrill Lynch:\n\nDesigned\/Modeled Logical\/Physical database schema to be used in automated testing.\n\nDatabase Admin\/upgrade\/Analysis\/Architect for Sybase 12\/Repserver 11.5.1. Resolution of complex problems in SQL Server\/Repserver, Performance and tuning.\n\n","position":"Software Engineer","startDate":"9\/2005","company":"AOL"},{"summary":"\n\nSybase DBA for SQL System 11 and 10 and Replication system 11 on HP-UX 10.\n\nModeled logical\/Physical schema for real-time trade and credit risk application\n\nSybase credit risk application development\/enhancement using C++\/Sybase.\n\nSybase real-time trade application enhancement using TCP\/IP and C++\/Sybase.\n\n","position":"Administrator","startDate":"4\/1998","company":"HSBC"},{"summary":"\n\nDB Trader interfaces on AIX 3.2.5\/RS6000 using Ksh and Perl 5.003, HTML Installed Perl 5.003 extensions\/modules. CGI Perl programming. Used IO, Socket, FTP, Sybperl modules. Used Cleo product for C3777\/C3780\/Async.\n\nWeb page development using Perl 5.003 CGI and HTML.\n\nInstalled Netscape Comm. Server (httpd) on AIX system and Apache on HP-UX 10.10. UNIX sysadmin of HP-UX 10.10 (SAM) and AIX (installp and smit) AIX qdaemon management. Wrote applications to utilize job queuing using AIX qdaemon.\n\nBuilt Real-time trade application using C++, Oracle\/ProC and TCP\/IP sockets to receive trades via TCP server and store in Oracle table for further processing. Built TCP Server\/Client.\n\nUsed sql*plus for command line sql utilities in Ksh.\n\nMOODY\u2019S INVESTOR SERVICES, Sybase Professional ","position":"Developer","startDate":"3\/1997","company":"BANK"},{"summary":"\n\nEvent job scheduling using Control-M and time-based job scheduling using Unix cron .\n\nTroubleshot Repserver 10.1.1, SQL Server 10\/11 and SQL Anywhere on AIX 4.1.4\/RS6000\/SP2 platform.\n\nBMC Patrol setup for monitoring Sybase processes.\n\nWrote DBTOOLS in shell to report tables, replication definitions and subscriptions.\n\nBuilt tools to automate adding of replication definitions, activation, and validation, etc.\n\nAutomated adding\/initializing of raw Unix devices to the ASE server using shell script identifying raw devices owned by Sybase on the machine that is not already defined in the ASE Server.\n\n","position":"Consultant","startDate":"7\/1996"},{"summary":"\n\nAdministered Sybase 10.2.0.4 for the production systems which include creating databases, producing dumps, generating reports daily showing space usage, allocation, permissions, managing users and their problems etc.\n\nHP\/UX System Administrator. Tools in Shell, Perl, Sybperl, sybtcl, and Tcl\/Tk.\n\nDesigned and developed C++\/Sybase\/DBLIB Real time trade application as TCP\/IP Server\/Client on HP\/UX 10.0 and Sybase 10.0.2.4 system to receive Trade transactions from Data General\/AOS system in Real time and download into Sybase tables and later transfer the records to AS\/400 system via MDI Gateway running on Windows\/NT platform using C++, DBLIB, CTLIB, stored procedures, triggers. Designed database schema of Sybase tables.\n\nDesigned and developed a Trading application for Credit risk management using C++ to load trading data from flat file to Sybase tables and process using Stored Procedures and transfer via MDI\/AS400 Gateway on Windows\/NT from UNIX to AS400. Converted Oracle applications to Sybase. Tested Sybase System 11 on HP-UX 10. Designed the database schema.\n\nLEHMAN BROTHERS, Database ","position":"Developer","startDate":"5\/1996","company":"HSBC"},{"summary":"\n\nSupported 20 SQL Servers as Sybase DBA. Duties included built scripts for dumps, monitoring space utilization, generating reports, performance tuning, maintaining warm backup, mirroring, automatic paging on errors, physical\/logical design etc.\n\nProvided Sybase DBA\/gateway support to applications accessing Sybase\/DB2 from PC using Power Builder and SUN\/Unix.\n\nDeveloped SYBASE and DB2 SQL financial application programs in \"C\".\n\nDeveloped SYBASE-DB2 gateway applications on Mainframe\/C and Unix\/C using SYBASE DBLIB.\n\nInstalled Sybase SQL 10.0\/Replication Server on Solaris machines and tested replication model.\n\nDeveloped RPC client and X-window client on Mainframe in \"C\" used to start processes on SUN.\n\nDeveloped RPC server on SUN, GUI applications using Xview and xHLLAPI programs on SUN in \"C\".\n\nDeveloped Shell scripts including batch fsql\/isql for updating SYBASE automatically which gets invoked by RPC from Mainframe.\n\nDeveloped \"Pager Client\" on Mainframe to communicate with SUN\/Unix \u201CPager Server\" over TCP\/IP in \"C\".\n\nDeveloped Pager client on PC using Chameleon's\/Novell's TCP\/IP to communicate with SUN Pager Server.\n\nMainframe batch\/JCL procedure to automate file transfer from Mainframe to SUN, Mainframe\/MVS, Mainframe\/VM,PC using TCP\/IP using \"C\",REXX\/EXEC.\n\nSystem installation\/Administration of Infohub on Mainframe to allow SQL access to non-SQL Mainframe data like VSAM, IDMS, Adabase, IMS, and Flat files from UNIX or DOS\/Windows platform.\n\nSystem installation\/Administration of Sybase Open Server 3.0\/Client 2.0.1 on Mainframe\/CICS and SUN\/Unix for accessing DB2 from PC\/Windows or SUN\/Unix OR Sybase from Mainframe\/CICS.\n\nEvaluated UNIX 3270 emulation packages from SUN\/IBM\/Openconnect.\n\nTaught \"C\" to application developers several times.\n\nInstalled IBM MQ-Series and Middleware from Peer Logic.\n\nSALOMON BROTHERS, Database ","position":"Developer","startDate":"8\/1995"},{"summary":"\n\nDeveloped application software under SUN OS\/Openwindows 3.0 using C\/C++. Universal communication Gateway between UNIX applications (sockets) and Mainframe applications (LU6.2) going to CICS\/DB2 or IMS adaptor\/IMS using MITEK\/SUNLINK box.\n\nDeveloped object oriented Gateway and socket Library and an inetd daemon in C and in C++. Secure communication software similar to KERBEROS using SYBASE, X-window. Built a shared library.\n\nXview applications provided GUI interfaces for Monitoring machines using RPC and modified existing X-Window applications.\n\nSCCS and Software Management control with proper make files. Administered a SUN\/Sparc machine.\n\n","position":"Developer","startDate":"4\/1992"},{"summary":"\/C Programmer\/System Designer 1977-1984\n\nTIFR, Scientific Officer (Hardware\/Software Design) 1973-1977\n\nPage 1 of 9\n\nPage 3 of 9","position":"Administrator","startDate":"1984-1991","company":"AT&T"}],"basics":{"phone":["732-972-7741","732-972-7741"],"email":["vka3@yahoo.com","vka3@yahoo.com"],"name":"AGARWAL ","label":"Developer"},"education":[{"Patents: Patents":": Multimaster Bus Arbitration scheme for intelligent controllers.\n\n"},{"Education & Training":":\n\nRutgers University: MSCS : 52 Credits; GPA: 3.63\/4\n\nI.I.T. Kanpur: BSEE : 120 credits; Overall GPA: 3.64\/4; EE Major GPA: 3.74\/4\n\nCompleted coursework\/training throughout career focused on technology and finance.\n\nBrainBench Certifications: Sybase 11.x Administration, UNIX Ksh, C++, UNIX Admin, Java 2\n\n"}]}